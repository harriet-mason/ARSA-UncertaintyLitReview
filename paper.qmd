---
title: "The Noisy Work of Uncertainty Visualisation Research: A Review"
author: Harriet Mason
bibliography: references.bib
date: last-modified
toc: true
number-sections: true
format: pdf
fig-valign: bottom
cap-location: bottom
editor_options: 
  chunk_output_type: console
---

<!-- TODO 
- convert to American spelling
- May not need to reference the same paper again and again
  - I am not sure when I need a citation and when I dont. Sometimes I could literally cite hundreds of papers to make a point, so I'm not sure if i should cite any at all.
- examples that aren't maps? Sure are a lot of maps.
-->

```{r}
#| echo: false
#| message: false
#| warning: false


# load Libraries
library(tidyverse)
library(biscale)
library(RColorBrewer)
library(scales)
library(sf)
library(ggrepel)
library(urbnmapr)
```

{{< pagebreak >}}

# Background

From entertainment choices to news articles to insurance plans, the modern citizen is so over run with information in every aspect of their life it can be overwhelming. In this overflow of information, tools that can effectively summarize information down into simple and clear ideas become more valuable. Information visualisations remain one of the most powerful tools for fast and reliable science communication. 

Visualization is an important step in exploratory data analysis and it is often utilised to **learn** what is important about a data set. Datasets such as Anscombe's quartet [@anscombe] or the Datasaurus Dozen [@datasaurpkg] highlight this power in visualisation. Additionally, visualisations allow for efficient and memorable communication. Even something as simple as sketching a distribution before recalling statistics or making predictions can greatly increase the accuracy of those measures [@Hullman2018; @Goldstein2014]. 

Uncertainty visualisation is a relatively new field in research. Early papers that specifically reference "uncertainty visualisation" appear in the late 80s [@Ibrekk1987], with geospatial information visualisation literature in the early 90s declaring this to be essential aspect of information display [@MacEachren1992; @Carr1992]. These early experiments typically involved showing participants a distribution, such as those depicted in @fig-ibrekk, and asking the viewers to extract a probability or average. Despite the new terminology visualisation of uncertainty has been present since the earliest times. For example, box plots or histograms can be considered to be displaying uncertainty in the sense of variability in observations sampled from a population distribution. Today, there is an abundance of publications on the topic which makes it is timely to construct a review of the field. In fact, there have already been several reviews published. 

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-ibrekk
#| fig-cap: "A replication of the the uncertainty visualisations shown by @Ibrekk1987 in one of the earliest uncertainty visualisation experiments. This early experiment is a good example of many of the issues that are still common in uncertainty visualisation today. For example, the '95% confidence interval' is more accurately a '95% prediction interval'. Additionally graphics that depict different mathematical objects that are also different on their visual components are compared because of a percieved relation to uncertainty. So visualisations of the mean, PDF and CDF, are all discussed as though they all contain the relevant statistical information. The axis also have different scales, and visualisation methods that are now unpopular for displaying proportions, such as a pie chart, are used."
#| fig-subcap: 
#|   - "Picture 1"
#|   - "Picture 2"
#|   - "Picture 3"
#|   - "Picture 4"
#|   - "Picture 5"
#|   - "Picture 6"
#|   - "Picture 7"
#|   - "Picture 8"
#|   - "Picture 9"
#| layout-ncol: 3

# Generate data
set.seed(1)
x=rnorm(1000, 8, 4)
ib_data <- tibble(x=ifelse(x<0, -x, x))

# Picture 1
p1 <- ib_data %>%
  summarise(avg = mean(x),
          conf_95a = quantile(x, probs=c(0.025)),
          conf_95b = quantile(x, probs=c(0.975))) %>%
  ggplot(aes(y="NA")) +
  geom_point(aes(x=avg)) +
  geom_errorbar(aes(xmin = conf_95a, xmax = conf_95b), width = 0.1) +
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks=seq(0,19),
                     labels= ggplot2:::interleave(as.character(c(seq(0,18, 2), 19)), rep("", 11))[c(0:19, 21)],
                     limits=c(0,19)) +
  theme_classic() +
  theme(axis.line.y=element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        aspect.ratio=1/10)

  
# Picture 2
p2 <- ib_data |>
  mutate(x = ifelse(x>18, 18, x),
         binx = cut(x, breaks=seq(0,18,2))) |>
  group_by(binx) |>
  summarise(n = n()) |>
  mutate(Probability = n / sum(n)) |>
  ggplot(aes(x=binx, y=Probability)) +
  geom_col(fill="black", colour="white") +
  scale_x_discrete(name = "INCHES OF SNOW",
                   labels= paste0(seq(0,16,2), sep = "-", seq(2,18,2))) +
  scale_y_continuous(breaks = seq(0.00, 0.25, 0.05)) +
  theme_classic() + 
  theme(aspect.ratio=0.33)

# Picture 3
# library(ggpattern)
p3 <- ib_data |>
  mutate(x = ifelse(x>18, 18, x),
         binx = cut(x, 
                     breaks=seq(0,18,2), 
                     labels= paste0(seq(0,16,2), sep = "-", seq(2,18,2)))) |>
  group_by(binx) |>
  summarise(n = n()) |>
  mutate(Probability = n / sum(n),
         csum = rev(cumsum(rev(Probability))), 
         pos = Probability/2 + lead(csum, 1),
         pos = if_else(is.na(pos), Probability/2, pos)) |>
  ggplot(aes(x="", y=Probability, fill=binx)) +
  geom_bar(stat="identity", width=1) +
  geom_text_repel(aes(y = pos, label = paste0(round(Probability*100), sep="", "%")),
                   size = 3, nudge_x = 0.6, show.legend = FALSE, segment.color = 'transparent') +
  #geom_label(aes(label = paste0(round(Probability*100), sep="", "%")),
  #          position = position_stack(vjust = 0.5)) + 
  scale_fill_grey() +
  coord_polar("y", start=0) +
  labs(fill = "INCHES OF SNOW") + 
  theme_void() + 
  theme(aspect.ratio=1)

# Picture 4
p4 <- ib_data |>
  ggplot(aes(x=x)) +
  geom_density() + 
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks = seq(0,20,2),
                     labels= paste0(seq(0,20,2))) +
  scale_y_continuous(name = "Probability density",
                     breaks = seq(0.00, 0.20, 0.02)) +
  theme_classic() + 
  theme(aspect.ratio=0.33)



# Picture 5
p5 <- ib_data |>
  ggplot(aes(y="", x=x)) +
  geom_violin() + 
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks = seq(0,20,2),
                     labels= paste0(seq(0,20,2)),
                     limits=c(0,20)) +
  theme_classic() + 
  theme(axis.line.y=element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        aspect.ratio=0.4)

# Picture 6
set.seed(1)
x=rnorm(5000, 8, 4)
ib_data2 <- tibble(x=ifelse(x<0, -x, x)) |>
  mutate(x=ifelse(x>=18, 18-rexp(5000,rate=0), x))
p6 <- ib_data2 |>
  ggplot(aes(y="", x=x)) +
  geom_jitter(size=0.05) + 
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks = seq(0,20,2),
                     labels= paste0(seq(0,20,2)),
                     limits=c(0,20)) +
  theme_classic() + 
  theme(axis.line.y=element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        aspect.ratio=0.1)


# Picture 7
p7 <- ib_data2 |>
  arrange(x) |>
  mutate(group = rep(1:50, each=100))|>
  group_by(group) |>
  summarise(x = max(x, na.rm=TRUE)) |>
  add_row(group=c(0,51), x = c(0,20)) |>
  ggplot(aes(x=x)) +
  geom_linerange(ymin = 0.1, ymax = 1) + 
  geom_linerange(y=1, xmin = -0.03, xmax = 20.03)+ 
  geom_linerange(y=0.1, xmin = -0.03, xmax = 20.03)+ 
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks = seq(0,20,2),
                     labels= paste0(seq(0,20,2)),
                     limits=c(0,20)) +
  scale_y_continuous(limits=c(0,1)) + 
  theme_classic() + 
  theme(axis.line.y=element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        aspect.ratio=0.1)

# Picture 8
p8 <- ib_data %>%
  reframe(x = quantile(x, probs=c(0.25, 0.50, 0.75)))|>
  add_row(x = c(0,20)) |>
  arrange(x) |>
  mutate(quantile = c("min", "q1", "med", "q3", "max")) |>
  pivot_wider(names_from = quantile, values_from = x) |>
  ggplot(aes(y="")) +
  #geom_point(aes(x=med)) +
  geom_errorbar(aes(y="", xmin = min, xmax = max), width = 0.2) +
  geom_crossbar(aes(y="", x=med, xmin = q1, xmax = q3), width = 0.5) +
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks=seq(0,20),
                     labels= ggplot2:::interleave(as.character(c(seq(0,20, 2))), rep("", 11))[1:21],
                     limits=c(0,20)) +
  theme_classic() +
  theme(axis.line.y=element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        aspect.ratio=1/10)


# Picture 9
p9 <- ib_data |>
  ggplot(aes(x)) +
  stat_ecdf(geom = "step") +
  scale_x_continuous(name = "INCHES OF SNOW",
                     breaks=seq(0,20),
                     labels= ggplot2:::interleave(as.character(c(seq(0,20, 2))), rep("", 11))[1:21],
                     limits=c(0,20)) +
  scale_y_continuous(name = "Cumulative probability",
                     breaks=seq(0,1,0.1),
                     labels= seq(0,1,0.1),
                     limits=c(0,1)) +
  theme_classic() +
  theme(aspect.ratio=4/10)

# Display Plots
p1
p2
p3
p4
p5
p6
p7
p8
p9
```


Reviews on uncertainty visualisation rarely offer tried and tested rules for effective uncertainty visualisation, but rather comment on the *difficulties* faced when trying to summarize the field. @Kinkeldey2014 found most experiments on the methods for uncertainty visualisation evaluation to be ad hoc, with no commonly agreed upon methodology or formalisation and no greater goal of describing general principals. @Hullman2016 commented on the difficulty in taking overarching themes from uncertainty visualisation, as several conflated issues make it unclear if subjects did poorly in an experiment because they misunderstood a visualisation, because the question was misinterpreted, or because they used a specific heuristic. @Spiegelhalter2017 commented that different plots are good for different things, and disagreed with the goal of identifying a universal "best" plot for all people and circumstances. @Griethe2006 was unable to find common themes, but instead listed the findings and opinions of a collection of papers. @uncertchap2022 summarized several cognitive effects that have repeatedly arised in uncertainty literature, however these effects were each discussed in isolation as a list of considerations an author might make. While these reviews are thorough in scope, none discuss how the existing literature contribute to the commonly state goal of uncertainty visualisation, scientific transparency. The problem faced by the literature is easily summarized with a famous quote by Henri Poincaré.

> "Science is built up of facts, as a house is built of stones; but an accumulation of facts is no more a science than a heap of stones is a house." - Henri Poincaré (1905)

That is to say, despite the wealth of reviews, the field of uncertainty visualisation remains a heap of stones. This review attempts to address this issue by offering a novel perspective on the uncertainty visualisation problem, and hopefully laying the foundations on which we can build a house. 

This review is broken into several parts that each reflect a different approach to uncertainty visualisation. First we look at graphics that ignore uncertainty entirely and discuss why uncertainty should be included at all. Second, we look at methods that consider uncertainty to be just another variable and discuss the characteristics of uncertainty that make it a unique visualisation problem. Third, we look at methods that explicitly combine our estimate and its uncertainty and discuss if the visualisations created by these transformations are still "uncertainty visualisations". Fourth, we will discuss methods that implicitly include uncertainty by depicting a sample or original data in place of an estimate. Finally, we discuss how uncertainty visualisations can be effectively evaluated. When discussing each of these methods, we consider the *purpose* of uncertainty visualisation and comment on how effective each visualisation is at fulfilling that purpose.

## Example Data
Throughout this review, we will be looking at

```{r}
#| echo: false
#| message: false
#| warning: false


# seed for sampling
set.seed(1997)

# Get map data
my_map_data <- get_urbn_map("counties", sf = TRUE) |>
  dplyr::filter(state_name=="Iowa")
centroids <- as_tibble(rgeos::gCentroid(as(my_map_data$geometry, "Spatial"), byid = TRUE))
my_map_data$cent_long <- centroids$x
my_map_data$cent_lat <- centroids$y
n <- dim(my_map_data)[1]

# Make standard Palette
# set Base colours
basecols <- brewer.pal(8, name = "YlOrRd")
#breaks <- seq(0,41, length.out = 9)
breaks <- 21:29 #c(0,15,24,25,26,27,30,35,41)
names(basecols) <- seq(8)
limits <- c(10,41)

my_map_data <- my_map_data |>
  dplyr::mutate(temp = 28 - ((scale(cent_long))^(2) + (scale(cent_lat))^(2))[,1], # trend
         notrend = rnorm(n), # no trend
         highvar = runif(n, min=2, max=4), # high variance
         lowvar = runif(n, min=0, max=2), # low variance
         ) |>
  pivot_longer(cols=highvar:lowvar, names_to = "variance_class", values_to = "variance") |>
  # add bivariate classes to data
  mutate(bitemp = cut(temp, breaks=breaks, labels=seq(8)),
         bivar = cut(variance, breaks=0:4, labels=seq(4)),
         biclass = paste(bitemp, bivar, sep="-")
  )


```
Due to the fields origins and focus in geospatial information visualisation, there have been a large number of suggested variations on the choropleth map that allow authors to include uncertainty. We will use these maps to provide simple examples for each approach that can be easily compared to the "no uncertainty" choropleth map to better understand the costs and benefits of each approach. Despite the example of each method focusing on variations of the choropleth map, it is important to understand that the approaches we are discussing are universal and are not unique to maps.

{{< pagebreak >}}

# Ignoring uncertainty
A good place to start might be at deceptively straight forward question, why should we include uncertainty at all? 

## What is uncertainty


## The choropleth map
@fig-choropleth depicts a choropleth map of the counties of Iowa. Each of these counties are colored according to an estimate of average daily temperature that was simulated so that the values followed a clear spatial trend (hot in the middle of the map, and cold on the outside). The variance of these estimates were simulated such that a hypothesis test would indicate the existence of a spatial trend in the low variance map, while the trend in the high variance map should be indistinguishable from noise. Is this distinction in validity of the spatial trend clear in in the map? Is the validity of the trend communicated through the visualisation?

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-choropleth
#| fig-cap: "Two choropleth maps that depict the counties of Iowa where each country coloured acording to a simulated average temperature. Both maps depict a spatial trend, where counties closer to the center of the map are hotter than counties on the edge of the map. This trend is only technically there in the low variance condition, i.e. if we performed a hypothesis test we would conclude the trend exists. The high variance condition displays a spatial trend that could simply be the result of noise, which means the plot is displaying a false conclusion."
#| fig-subcap: 
#|   - "Low Variance Data"
#|   - "High Variance Data"
#|   - "Choropleth Palette"
#| layout-ncol: 3
#| layout-valign: "bottom"
#| cap-location: "bottom"


# Choropleth Map
p1a <- my_map_data |>
  filter(variance_class=="lowvar") %>%
  ggplot() +
  geom_sf(aes(fill = bitemp, 
              geometry = geometry), colour=NA) + 
  scale_fill_manual(values = basecols) +
  #scale_fill_gradientn(colours = basecols, 
  #                     values=breaks/limits[2],
  #                     limits=limits) +
  theme_void() + 
  theme(legend.position = "none")

p1b <- p1a %+% filter(my_map_data, variance_class=="highvar")

show_pal <- function (colours, borders = NULL, cex_label = 1, ncol = NULL, myxlab, breaks) {
  # Set dimensions of palette
  n <- length(colours)
  ncol <- ncol %||% ceiling(sqrt(length(colours)))
  nrow <- ceiling(n/ncol)
  # make matrix with null values (if not full)
  colours <- c(colours, rep(NA, nrow * ncol - length(colours)))
  colours <- matrix(colours, ncol = ncol, byrow = TRUE)
  # set graphical parameters (?)
  old <- par(pty = "s", mar = c(0, 0, 0, 0))
  on.exit(par(old))
  size <- max(dim(colours))
  plot(c(0, size), c(0, -size), type = "n", xlab = "", ylab = "", 
      axes = FALSE)
  rect(col(colours) - 1, -row(colours) + 1, col(colours), -row(colours), 
       col = colours, border = borders)
  text(c(0,col(colours)) + c(0.2, 0.1, 0,0,0,0,0,-0.1,-0.2), -c(1,row(colours))-0.25, breaks, 
              cex = 1, col = "black")
  text(4, -1.75, myxlab ,cex = 1.5, col = "black")
}

p1a
p1b

show_pal(basecols, ncol=8, borders=NA, myxlab = "Temperature", breaks = 21:29)

```

## Signal-supression
The two choropleth maps appearing to be identical in @fig-choropleth highlights the need for uncertainty visualisations. Uncertainty visualisation is is required for transparency and this sentiment has been repeated.  Some authors suggest uncertainty is important to include as it communicates the legitimacy (or illegitimacy) of the conclusion drawn from visual inference [@Correll2014; @Kale2018; @Griethe2006]. Some authors have said that uncertainty should be included to degree of confidence or trust in the data [@Boukhelifa2012; @Zhao2023]. Some authors directly connect uncertainty visualisation to hypothesis testing as it ensures the "validity" of a statement [@Hullman2020a; @Griethe2006], but allows for a proportional level of trust that is more detailed than the binary results of a hypothesis test [@Correll2014; @Correll2018]. Some authors even go so far as to claim that failing to include uncertainty is akin to fraud or lying [@Hullman2020a; @Manski2020].

This consensus leads us to understand that uncertainty visualisation is motivated by the need for a sort of "visual hypothesis test". A successful uncertainty visualisation would act as a "statistical hedge" for any inference me make using the graphic. Additionally, since the purpose of a visualisation is to give a quick "gist" of the information [@Spiegelhalter2017], this hedging needs to be communicated visually without any need for computation from the viewer. Additionally, @Ndlovu2023 found that participants applied the same methods they used for simple choropleth maps to complicated uncertainty maps even if that take away was invalid. Therefore, this hedging effect needs to be communicated simply through the visualisation. If we refer to the conclusion we draw from a graphic to be its "signal" and the variance that makes this signal harder to identify as the "noise", we can summaries this information into three key requirements. A good uncertainty visualisation needs to:

  1) Reinforce justified signals to encourage confidence in results
  2) Hide signals that are just noise to prevent unjustified conclusions
  3) Perform tasks 1) and 2) in a way that is proportional to the level of confidence in those conclusions.

As @fig-choropleth showed, visualisations that are unconcerned with uncertainty have no issue showing justified signals, but struggle with the display of unjustified signals. Therefore, we coin this approach to uncertainty visualisation as "signal-suppression" since it primarily differentiates itself from from the "noiseless" visualisation approach through criteria (2). That is, the main difference between an uncertainty visualisation and a "normal" visualisation is that an uncertainty visualisation should prevent us from drawing unjustified conclusions. 

{{< pagebreak >}}

## Uncertainty as a signal
Uncertainty visualisation is not only motivated by signal-suppression, and we would be remiss to ignore these alternative motivations. Some authors claim the purpose of uncertainty is to improve decision making [@Ibrekk1987; @uncertchap2022; @Hullman2016; @Cheong2016; @Boone2018; @Padilla2017]. Other authors do not describe uncertainty as important for decision making, but rather explicitly state it as variable of importance in of itself [@Blenkinsop2000]. While uncertainty can provide useful information in decision making, it is important to recognize the "uncertainty" in these cases is not acting as "uncertainty" at all. It is acting as signal. 

This is obvious for the cases where we are explicitly interested in the variance or error, as we are literally trying to draw conclusions about an "uncertainty" statistic. The same is true for "decision making" experiments, but it is less overt. This is easiest to understand with an example. Imagine you are trying to decide if you want to bring an umbrella with you to work. An umbrella is annoying to bring with you, so you only want to pack it if the chance of rain is greater than 10%. Unfortunately, your weather prediction app only provides you with the predicted daily rainfall. Therefore, your decision will be improved with the inclusion of uncertainty, *not* because uncertainty is important for your decision, but because it gives you the tools required to calculate the *actual* statistic you are basing your decision on. In this sense, uncertainty is no more "special" to decision making than weight is in a BMI calculation.

Uncertainty visualisation's made for these purposes should simply display the uncertainty statistic we are interested in, such as the variance, or probability of an event. This is precisely what we observe. @fig-exceed depicts an exceedance probability map that has was designed as an alternative to the choropleth map to improve decision making under uncertainty [@Kuhnert2018; @Lucchesi2021]. A keen viewer may notice that the "exceedance probability map" is actually just a choropleth map, only the statistic being displayed has changed. We do not believe this graphic be considered an uncertainty visualisation.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-exceed
#| fig-cap: "An exceedance probability map that depict the counties of Iowa where each country coloured acording to the probability that the average temperature exceeds 27. This map is a choropleth map where the variable of interest is a probability."
#| fig-subcap: 
#|   - "Low Variance Data"
#|   - "High Variance Data"
#|   - "Exceedance Probability Palette"
#| layout-ncol: 3
#| layout-valign: "bottom"

# quantile
prob_breaks <- seq(-0.1,1.1, length.out=9)
exeed_data <- my_map_data |> 
  as_tibble() |>
  mutate(xprob = 1- pnorm(27, mean=temp, sd=sqrt(variance))) |>
  mutate(xprob = cut(xprob, breaks=prob_breaks, labels=seq(8)))
             
# Exceed Prob Map
p2a <- exeed_data |>
  filter(variance_class=="lowvar") %>%
  ggplot() +
  geom_sf(aes(fill = xprob, 
              geometry = geometry), colour=NA) + 
  scale_fill_manual(values = basecols) +
  theme_void() + 
  theme(legend.position = "none")

p2b <- p2a %+% filter(exeed_data, variance_class=="highvar")

p2a
p2b
show_pal(basecols, ncol=8, borders=NA, myxlab = "Probability Temp>27", breaks = c(0, prob_breaks[2:8], 1))
```

There seem to be two different definitions of "uncertainty visualisation" floating around in the literature. The first considers *any* visualisation of error, variance, or probability to be an uncertainty visualisation. The second believes an "uncertainty visualisation" is the output of a function that takes a normal visualisation as an input, and transforms it to include the uncertainty information. The former group believe the purpose of uncertainty visualisation to provide signal about a distribution, while the later believe it should act as noise to obfuscate a signal. The lack of explicit distinction between these two motivations leaves the literature muddled and reviewers struggle to understand if uncertainty should be treated as a variable, as metadata, or as something else entirely [@Kinkeldey2014]. This disagreement creates constant contradictions in what the literature considers to be an "uncertainty visualisation". For example @Leland2005 mentions that popular graphics, such as pie charts and bar charts omit uncertainty, and @Wickham2011 suggests their product plot framework, which includes histograms and bar charts, should be extended to include uncertainty however at least one or both of these charts are used in a significant number of uncertainty visualisation experiments [@Ibrekk1987; @Olston2002; @Zhao2023; @Hofmann2012]. If you view uncertainty as a function applied to an existing graphic, then you would believe a pie chart and bar chart are not uncertainty visualisations, as they are yet to have the "uncertainty visualisation function" applied to them. If you view uncertainty as any graphic that depicts an "uncertainty statistic" then there are no limitations on which graphics can or cannot be uncertainty visualisations. 

When we use "uncertainty visualization" to refer to graphics that simply communicate a variance or probability, we are classifying  visualisations by the data they display, not their visual features. Graphics, just like statistics, are not defined by their input data. A scatter plot that compares mean and a scatter plot that compares variances are both scatter plots. Given that there is no special class of visualisation for *other* statistics (such the median or maximum) there is no reason to assume visualisations that simply depict a variance, error, or probability to be special. Some authors implicitly suggest that that visualisations of variance or probability are differentiated due to the psychological heuristics involved in interpreting uncertainty [@Hullman2019]. While it is true that heuristics lead people to avoid uncertainty [@Spiegelhalter2017] there is no evidence that this psychological effect translates to issues with the visual representation of uncertainty. Again, given that we do not make these same visual considerations for other variables that elicit distaste or irrational behavior, there is no reason to assume this is what makes uncertainty visualisation so special. 

This leads us to the conclusion that the visualisations made for the purpose of displaying information about uncertainty statistics are not uncertainty visualisations. These graphics are just normal information visualisations, and authors can follow existing principles of graphical design. We will focus on the perspective that uncertainty visualisation serves to obfuscate signal, and an uncertainty visualisation is a variation on an existing graphic that gives it the ability to suppress false signals. 

Of course, we do not believe there is anything wrong with explicitly visualizing variance, error, bias, or any other statistic used to depict uncertainty as a signal. Just like any other statistic, these metrics provide important and useful information for analysis and decisions. However, there is no interesting visualisation challenge associated with these graphics, and they do not require any special visualisation. The uncertainty in these graphics are acting as a signal variable, and they should be treated as such. 


{{< pagebreak >}}

# Visualising uncertainty as a variable
Upon hearing that uncertainty needs to be included for transparency, the solutions may seem obvious. You may think "well, I will just add a dimension to my plot that includes uncertainty". This makes sense, as this is the simplest way to add uncertainty to an existing graphic is to simply map uncertainty to an unused visual channel. 

## The bivariate map
@fig-bivariate a variation of the choropleth map, where we have a two dimensional color palette. Not only is temperature mapped to hue, but variance is also mapped to saturation. While these two maps *do* look visually different (which was not the case in the choropleth map) the spatial trend is still clearly visible in both graphics. This means the uncertainty *is technically* being communicated, however the primary take away in the graphic is the spatial trend (that does not exist). The graphic did not hide the invalid signal, so it is not performing signal-suppression as we would like. At this point, it might be reasonable to ask, why? Why is including the uncertainty as a variable insufficient to achieve signal-suppression, and what changes should we make to ensure signal-suppression occurs?

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-bivariate
#| fig-cap: "A bivariate map that depict the counties of Iowa where each county is coloured acording to it's average daily temperature and the variance in temperature. This map is a choropleth map with a two dimensional colour palette where temperature is represented by colour hue, and variance is represented by colour saturation. Even though uncertainty has been added to the graphic the spatial trend is still clearly visible in the case where the spatial trend could be attributed to noise."
#| fig-subcap: 
#|   - "Low Variance Data"
#|   - "High Variance Data"
#|   - "Bivariate Palette"
#| layout-ncol: 3
#| layout-valign: "bottom"

# Bivariate Map
# Make bivariate palette
# Function to devalue by a certain amount
colsupress <- function(basecols, hue=1, sat=1, val=1) {
    X <- diag(c(hue, sat, val)) %*% rgb2hsv(col2rgb(basecols))
    hsv(pmin(X[1,], 1), pmin(X[2,], 1), pmin(X[3,], 1))
}

# recurvisely decrease value
v_val = 0.5
bivariatepal <- c(basecols,
                  colsupress(basecols, sat=v_val),
                  colsupress(colsupress(basecols, sat=v_val), sat=v_val),
                  colsupress(colsupress(colsupress(basecols, sat=v_val), sat=v_val), sat=v_val))
# establish levels of palette
names(bivariatepal) <- paste(rep(1:8, 4), "-" , rep(1:4, each=8), sep="")

# Bivariate maps
p2a <- my_map_data |>
  filter(variance_class=="lowvar") %>%
  ggplot() +
  geom_sf(aes(fill = biclass, geometry = geometry), colour=NA) + 
  scale_fill_manual(values = bivariatepal) +
  theme_void() + 
  theme(legend.position = "none")
  
p2b <- p2a %+% filter(my_map_data, variance_class=="highvar")

show_pal2 <- function (colours, borders = NULL, cex_label = 1, ncol = NULL, myxlab, myylab, breaks, breaks2) {
  # Set dimensions of palette
  n <- length(colours)
  ncol <- ncol %||% ceiling(sqrt(length(colours)))
  nrow <- ceiling(n/ncol)
  # make matrix with null values (if not full)
  colours <- c(colours, rep(NA, nrow * ncol - length(colours)))
  colours <- matrix(colours, ncol = ncol, byrow = TRUE)
  # set graphical parameters (?)
  old <- par(pty = "s", mar = c(0, 0, 0, 0))
  on.exit(par(old))
  size <- max(dim(colours))
  plot(c(-1.5, size), c(0, -size), type = "n", xlab = "", ylab = "", 
      axes = FALSE)
  rect(col(colours) - 1, -row(colours) + 1, col(colours), -row(colours), 
       col = colours, border = borders)
  text(c(0,col(colours)[nrow,]) + c(0.2, 0.1, 0,0,0,0,0,-0.1,-0.2) , -4.5, 
       breaks, cex = 1, col = "black")
  text(-0.25, -c(0,row(colours)[,ncol]) + c(-0.2, -0.1, 0, 0.1, 0.2),
       breaks2, cex = 1, col = "black")
  text(4, -5.5, myxlab ,cex = 1.5, col = "black")
  text(x=-1.25,y=-2, myylab, srt=270, cex = 1.5, col = "black")
}

p2a
p2b
show_pal2(colours = bivariatepal, ncol=8, borders=NA, myxlab = "Temperature", myylab = "Variance", breaks = 21:29, breaks2 = 0:4)
```

## Why this approach may (or may not) work
The difficulty in incorporating uncertainty into a visualisation is frequently mentioned but seldom explained. For example @Hullman2016 commented that it is straightforward to show a value but it is much more complex to show uncertainty but did not explain why. Many authors seem to believe uncertainty visualisation is a simple high-dimensional visualisation problem, as the difficulty comes from working out how to add uncertainty into already existing graphics [@Griethe2006]. The problem with this approach to uncertainty visualisation is that it treats uncertainty the same as we would any other variable. However, @fig-bivariate makes it clear that simply including uncertainty as a variable is insufficient to perform signal-suppresion. If we cannot treat uncertainty as any other variable, what should we treat it as? We need to understand what uncertainty actually *is*, in order to understand how to integrate it into a visualisation.

### It's a variable... it's a metadata... it's uncertainty?
Describing what uncertainty actually is, is surprisingly hard. Most authors simply avoid the problem and describe the characteristics of uncertainty, of which there are plenty. Often, uncertainty is split using an endless stream of ever changing boundaries, such as whether the uncertainty is due to true randomness or a lack of knowledge [@Spiegelhalter2017; @Hullman2016; @utypo], if the uncertainty is in the attribute, spatial elements, or temporal element of the data [@Kinkeldey2014], whether the uncertainty is scientific (e.g. error) or human (e.g. disagreement among parties) [@Benjamin2018], if the uncertainty is random or systematic [@Sanyal2009], statistical or bounded [@Gschwandtnei2016; @Olston2002], recorded as accuracy or precision [@Griethe2006; @Benjamin2018], which stage of the data analysis pipeline the uncertainty comes from [@utypo], how quantifiable the uncertainty is [@Spiegelhalter2017; @utypo], etc. There are enough qualitative descriptors of uncertainty to fill a paper, but, none of this is particularly helpful in understanding how to integrate it into a visualisation. 

Rather than trying to define uncertainty by what it *is* it may be easier to try and describe what uncertainty *is not*. Descriptive statistics describe our sample as it is and summarizes large data down into an easy to swallow format. Descriptive statistics are not seen as the primary goal of modern statistics, however, this was not always the case. In 19th century England, *positivism* was the popular philosophical approach to science (positivists included famous statisticians such as Francis Galton and Karl Pearson). Practitioners of the approach believed statistics ended with descriptive statistics as science must be based on actual experience and observations [@Otsuka2023]. In order to make statements about population statistics, future values, or new observations we need to perform inference, which requires the assumption of the "uniformity of nature", i.e. we need to assume that unobserved phenomena should be similar to observed phenomena [@Otsuka2023]. Positivists abhore the assumption of the "uniformity of nature" as they believed referencing the unobservable is bad science. In other words, these scientists embraces descriptive statistics and shunned inferential statistics due to the inherent uncertainty that came with them. Uncertainty is a by-product of inference.

This history lesson illustrates what uncertainty actually is. At several stages in a statistical analysis, we will violate the "uniformity of nature" assumption. Each of these violations will impact the statistic we have calculated and push it further from the population parameter we wish to draw inference on. Uncertainty is the amalgamation of these impacts. If we do not violate the uniformity of nature assumption at any point in our analysis, we do not have any uncertainty.

This interpretation of uncertainty indicates that the uncertainty on a statistic is not of value in of itself. Uncertainty is metadata about our statistic that is required for valid inference. This means uncertainty should not be visualised by itself and we should seek to display signal and uncertainty together as a "single integrated uncertain value" [@Kinkeldey2014]. This aspect of uncertainty visualization makes it a uniquely difficult problem. This is something frequently mentioned 


### Visualising the "single integrated uncertain value"
Typically, when making visualisations, we want the visual channels to be separable, that is, we don't want the data represented through one visual channel to interfere with the others [@Smart2019]. Mapping uncertainty and signal to separable channels allows them to be read separately, which does not align with the goal of communicating them as a "single integrated channel". Additionally, visualizing uncertainty and signal separately allows the uncertainty information to simply be ignored, which is a pervasive issue in current uncertainty visualisation methods [@uncertchap2022]. We can see this problem in @fig-bivariate, as it sends the message "this data has a spatial trend and the estimates have a large variance" as we read the signal and the uncertainty separately.

This means effective uncertainty visualisation should be leveraging integrability. That is, the visual channels of the uncertainty and the signal would need to be separately manipulable, but read as a single channel by the human brain. While most visual aesthetics *are* separable, there are some variables that have been shown to be integrable, such as color hue and brightness [@Vanderplas2020]. When visualizing uncertainty using its own visual channel, we can also consider visual semiotics and make sure to map uncertainty to intuitive visual channels, such as mapping more uncertain values to lighter colors [@Maceachren2012].

```{r}
#| echo: false
#| message: false
#| warning: false
#| eval: false
#| label: fig-bivariate2
#| layout-ncol: 3
#| layout-valign: "bottom"

#fig-cap: "A bivariate map that depict the counties of Iowa where each county is coloured acording to it's average daily temperature and the variance in temperature. This map is a variation on the previous bivariate map where instead of variance being mapped to colour saturation, it is mapped to colour value. Even though colour value is intergrable with colour hue, and colour value is naturally accociated with uncertainty, the spatial trend is still visible in the map."

# Bivariate Map
# Make bivariate palette
# Function to devalue by a certain amount
colsupress2 <- function(basecols, hue=1, sat=1, val=1) {
    X <- diag(c(hue, sat, val)) %*% rgb2hsv(col2rgb(basecols))
    hsv(pmin(X[1,], 1), pmin(X[2,], 1), pmin(X[3,], 1))
}

# recurvisely decrease value
v_val = 1.1
bivariatepal2 <- c(basecols,
                   colsupress2(basecols, val=v_val), 
                   colsupress2(colsupress2(basecols, val=v_val), val=v_val),
                   colsupress2(colsupress2(colsupress2(basecols, val=v_val), val=v_val), val=v_val)
                   )

# establish levels of palette
names(bivariatepal2) <- paste(rep(1:8, 4), "-" , rep(1:4, each=8), sep="")

# Bivariate maps 2
p2a1 <- my_map_data |>
  filter(variance_class=="lowvar") %>%
  ggplot() +
  geom_sf(aes(fill = biclass, geometry = geometry), colour=NA) + 
  scale_fill_manual(values = bivariatepal2) +
  theme_void() + 
  theme(legend.position = "none")
  
p2b2 <- p2a1 %+% filter(my_map_data, variance_class=="highvar")


p2a1
p2b2
#show_pal2(colours = bivariatepal2, ncol=8, borders=NA, myxlab = "Temperature", myylab = "Variance", breaks = 21:29, breaks2 = 0:4)

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-transparency
#| fig-cap: "A bivariate map that depict the counties of Iowa where each county is coloured acording to it's average daily temperature and variance. This map is a variation on the previous bivariate map where instead of variance being mapped to colour saturation, it is mapped to transparency."
#| fig-subcap: 
#|   - "Low Variance Data"
#|   - "High Variance Data"
#|   - "Transparency Palette"
#| layout-ncol: 3
#| layout-valign: "bottom"

# ALTERNATIVE TRANSPARENCY INSTEAD OF COLOUR VALUE
# get colour values from transparency transformation
transpal <- lapply(basecols, scales::alpha, alpha=c(0.95, 0.65, 0.35, 0.05))

transpal <- as.vector(matrix(unlist(transpal), ncol = 4, byrow = TRUE))

names(transpal) <- paste(rep(1:8, 4), "-" , rep(1:4, each=8), sep="")

# Transparency maps
pta <- my_map_data |>
  filter(variance_class=="lowvar") %>%
  ggplot() +
  geom_sf(aes(fill = biclass, geometry = geometry), colour=NA) + 
  scale_fill_manual(values = transpal) +
  theme_void() + 
  theme(legend.position = "none")
  
ptb <- pta %+% filter(my_map_data, variance_class=="highvar")

pta
ptb
show_pal2(colours = transpal, ncol=8, borders=NA, myxlab = "Temperature", myylab = "Variance", breaks = 21:29, breaks2 = 0:4)

```

@fig-transparency is an example of a variations of @fig-bivariate where uncertainty is mapped to transparency, and temperature is mapped to color hue to leverage these visualisation concepts. This method achieves signal suppression quite well. The spatial trend is clearly visible in the low variance case and that trend it becomes much harder to identify in the high variance case. While this was an effective approach for this graphic, relying on integrability may not give us the amount of control we want over our signal-supresison. Without a strong understanding of how these visual channels collapse down into a single channel, relying on integrability could create unintended consequences such as displaying phantom signals or hiding justified signals. Additionally, multi-dimensional colour palettes can make the graphics harder to read and hurt the accessibility of the plots [@Vanderplas2015]. 

There is another reason @fig-transparency is better at signal-suppression than @fig-bivariate, and it may not be due to integrability. Colour value has a second desirable quality for signal-supression, which is that the colours become harder to distinguish as the value decreases. This means high uncertainty values are harder to differentiate than low uncertainty values. This implicit feature of colour value can generalised to other aesthetics by transforming the visual feature space ourselves.

{{< pagebreak >}}


# Visualising uncertainty and signal in a new space
Instead of hoping that uncertainty might collapse signal values into a single dimension, we can do some of that work ourselves, and uncertainty visualisation authors already have.

## Value Supressing Uncertainty Palettes
The Value Suppressing Uncertainty Palette (VSUP) [@Correll2018], was designed with the intention of preventing high uncertainty values from being extracted from a map. Since the palette was designed with the extraction of individual values in mind and it has only been tested on simple value extraction tasks [@Correll2018] or search tasks [@Ndlovu2023], it is unclear how effective the method is at suppressing broader insights such as spatial trends. 

@fig-vsup is a visualisation of the Iowa temperature data using a VSUP to color the counties. The low uncertainty case still has a visible spatial trend, while the spatial trend in the high uncertainty map has functionally disappeared. This means the VSUP has successfully suppressed the spatial trend in the data. However the spatial trend may not be the only signal of concern in our graphic. Now we must return to the original signal-suppression criteria and ask ourselves if they have all been met. Are all the justified signals reinforced, while all the unjustified signals are suppressed? Is a graphic that performs perfect signal-suppression even possible?

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-vsup
#| fig-cap: "A map made with a VSUP. The counties of Iowa are coloured acording to it's average daily temperature and the variance in temperature, although the space they have been mapped to is slightly warped. Similar to the bivariate map, temperature is mapped to hue while variance is mapped to saturation. This map successfully reduces the visibility of the spatial trend in the high uncertainty case while maintaining the visibility of the spatial trend in the low uncertainty case."
#| fig-subcap: 
#|   - "Low Variance Data"
#|   - "High Variance Data"
#|   - "VSUP Palette"
#| layout-ncol: 3
#| layout-valign: "bottom"

# VSUP
# Function to combine colours for VSUP
colourblend <- function(basecols, p_length, nblend) {
    X <- rgb2hsv(col2rgb(unique(basecols)))
    v1 <- X[,seq(1,dim(X)[2], 2)]
    v2 <- X[,seq(2,dim(X)[2], 2)]
    if("matrix" %in% class(v1)){
      # hue issue wrap around pt 1
      v3 <- (v1+v2)
      v3["h",] <- ifelse(abs(v1["h",]-v2["h",])>0.5, v3["h",]+1, v3["h",])
      v3 <- v3/2
      # hue issue wrap around pt 2
      v3["h",] <- ifelse(v3["h",]>=1 , v3["h",]-1 ,v3["h",])
      hsv(rep(v3[1,], each=nblend), rep(v3[2,], each=nblend), rep(v3[3,], each=nblend))
      } else {
        v3 <- (v1+v2)
        v3["h"] <- ifelse(abs(v1["h"]-v2["h"])>0.5, v3["h"]+1, v3["h"])
        v3 <- v3/2
        v3["h"] <- ifelse(v3["h"]>=1 , v3["h"]-1 ,v3["h"])
        rep(hsv(h=v3[1], s=v3[2], v=v3[3]), p_length)
        }
}

VSUPfunc <- function(basecols, p_length, nblend){
  colourblend(colsupress(basecols, sat=0.5), p_length, nblend)
}

# VSUP
p = length(basecols)
VSUP <- c(basecols,
          VSUPfunc(basecols, p, 2),
          VSUPfunc(VSUPfunc(basecols, p, 2), p, 4),
          VSUPfunc(VSUPfunc(VSUPfunc(basecols, p, 2), p, 4), p, 8))

names(VSUP) <- paste(rep(1:8, 4), "-" , rep(1:4, each=8), sep="")

# VSUP maps
p3a <- my_map_data |>
  filter(variance_class=="lowvar") %>%
  ggplot() +
  geom_sf(aes(fill = biclass, geometry = geometry), colour=NA) + 
  scale_fill_manual(values = VSUP) +
  theme_void() + 
  theme(legend.position = "none")

p3b <- p3a %+% filter(my_map_data, variance_class=="highvar")

p3a
p3b
show_pal2(colours = VSUP, ncol=8, borders=NA, myxlab = "Temperature", myylab = "Variance", breaks = 21:29, breaks2 = 0:4)

```



## What can and cannot be suppressed?
The methods used by the VSUP bring to light a slight problem with uncertainty visualisation. Specifically that uncertainty and the purpose of visualisation are somewhat at odds with one another. There are two primary motivations behind visualisation, communication and exploratory data analysis (EDA). Communication involves identifying a signal we want to communicate and designing a visualisation that best conveys that, while EDA involves creating a versatile visualisation using it to extract several signals. If we are designing an uncertainty visualisation for communication then we can just suppress the specific signal we are seeking to communicate. In the map example, we would consider @fig-vsup to be a success as the only signal we are concerned with is the spatial trend. However, it is not uncommon for authors to express a desire for uncertainty visualisations that perform signal-suppression in visualisations made for EDA [@Sarma2024; @Griethe2006]. For uncertainty visualisation for EDA to work, we would need to assume that suppressing individual estimates using their variance should naturally extend to broader suppression of plot level insights. Unfortunately it is not clear whether or not uncertainty visualisations for EDA are possible. 

### There is no uncertainty in EDA
Earlier we established that uncertainty is a by-product of inference, which means without inference, there is no uncertainty. Often EDA is used to give us an understanding of our data and identify which signals are worth pursuing. In this sense, EDA is the visual parallel to descriptive statistics, as it is performed without an explicit hypothesis which means there is no inference, and by extension, there is no uncertainty. 

Some authors recognize inference will occur (in some shape or form) and believe uncertainty *should* be visualised but do not recognize *how* uncertainty would be visualised. @Hullman2021 argued that there is no such thing as a "model-free" visualisation, therefore all visualisations require uncertainty as we are always performing inference. However, even something as simple as calculating the uncertainty that is used to suppress our visualisation is not model free, as we need to identify if the sampling variance or the sample variance is more appropriate [@Hofman2020]. While we agree that people cannot prevent themselves from performing inference, this does not mean it is possible to include uncertainty in a visualisation designed for EDA. However, this does mean we should endeavor for a versatile uncertainty visualisation method that is able to perform signal-suppression on all the signals displayed in the visualisation. 

Uncertainty visualisation for EDA would be possible if we designed a plot in such a way that suppressing individual estimates using their variance would naturally extend to broader suppression of plot level insights. This assumption is commonly made by visualisation researchers in normal visualisation experiments [@North2006], however achieving it would largely depend on the methods use to perform signal suppression. By manually combining the values in @fig-vsup, we violated this requirement, so the VSUP is not versatile enough to act as an uncertainty visualisation for EDA.

### The limitations of explicitly visualising uncertainty and signal
The lack of versatility of the VSUP is easy to see with a simple example. Let's say we have a graphic that depicts a set of coefficients from a linear regression and the value of the coefficient is shown using a single color. We want to know "Which of these coefficients are different from 0?" as well as "Which of these coefficients are different from each other?". To answer this question we do a series of t-tests on these estimates.

All of the individual t-tests of fail to reject the null hypothesis that the coefficients are different from 0. We then make a visualisation that suppresses this signal and ensures that all of the estimates are visually indistinguishable from 0. We then do a comparison of two means t-test and find that several of the values need to be visually distinguishable from each other. The VSUP method must pick a single color for each estimate, and these colors must be *either* visually distinguishable or indistinguishable from each other. We cannot perform signal-suppression on both these signals simultaneously.

This example highlights a fundamental problem with the VSUP that extends to the bivariate map as well. When we blend these colors, we need to decide at what level of *uncertainty* to blend these colors together. Even though the bivariate map does not explicitly combine color values at certain variance levels, the mapping of variance to color saturation does this implicitly. That is, at certain saturation values the colors in a bivariate map are imperceptibly different to the human brain and appear as though they are mapped to the same value. At this point, it is irrelevant whether or not the colours are technically different, they are the same color in the human brain.  Which hypothesis are suppressed and which are not largely depends on the method used to combining colors in the palette [@Kay2019]. The VSUP here used a tree based method as that is what was used by @Correll2018, but there are alternatives that are more appropriate for different hypothesis. 

If we only use a single value to express each signal-suppressed statistic, we will always need to decide which signals we suppress and which we do not. However, If we could express the statistic of a cell using multiple colors, this limitation may disappear entirely.

{{< pagebreak >}}

# Implicitly Combining Uncertainty and Signal
There is technically a stage of our analysis where the estimate and variance are not separate, when we only have a sample. Rather than trying to figure out how to combine signal and uncertainty into a single color, we can just display a sample instead and allow the viewer to extract *both* the estimate and the variance.

## Pixel map
@fig-pixel displays a pixel map [@Lucchesi2021], which is a variation of the choropleth map where each area is divided up into several smaller areas, each colored using outcomes from the larger area's temperature sampling distribution. The spatial trend is clearly visible in the low variance case, but functionally disappears in the low variance case. While the spatial trend is just barely visible in the high uncertainty case, it is much harder to see. This means the graphic also achieves the third criteria for signal-suppression, i.e. our difficulty in seeing the distribution is proportional to the level of uncertainty in the graphic. 

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-pixel
#| fig-cap: "A pixel map of the counties of Iowa. In this map, each county is broken up into several smaller regions and coloured according to a potential daily temperature, given the its average daily temperature and its sampling distribution. This results in each county being represented by a sample rather than a single value. In this graphic, we can clearly see the spatial trend in the low variance case, while the spatial trend is much harder to identify in the high variance case. "
#| fig-subcap: 
#|   - "Low Variance Data"
#|   - "High Variance Data"
#|   - "Pixel Map Palette"
#| layout-ncol: 3
#| layout-valign: "bottom"

# Pixel Map
library(Vizumap)

# Low variance map
my_map_data_a <- my_map_data %>%
  filter(variance_class == "lowvar") %>%
  mutate(my_id = seq(n),
         error = variance) 

# quantile
q_a <- my_map_data_a |> 
  as.tibble() |>
  mutate(bitemp=as.numeric(bitemp)) |>
  with(data.frame(p0.05 = qnorm(0.05, mean=bitemp, sd=sqrt(variance)),
                  p0.25 = qnorm(0.25, mean=bitemp, sd=sqrt(variance)), 
                  p0.5 = qnorm(0.5, mean=bitemp, sd=sqrt(variance)), 
                  p0.75 = qnorm(0.75, mean=bitemp, sd=sqrt(variance)), 
                  p0.95 = qnorm(0.95, mean=bitemp, sd=sqrt(variance))))|>
  apply(2, function(x) ifelse(x>8, 8, x)) |>
  apply(2, function(x) ifelse(x<0, 0, x))


pixel_1a <- my_map_data_a %>%
  as.data.frame() %>%
  select(my_id, bitemp, error) %>%
  read.uv(estimate="bitemp", error="error")

pixel_2a <- my_map_data_a %>% as("Spatial")

pix_a <- pixelate(pixel_2a, pixelSize = 3, id = "my_id")

pmap_a <- build_pmap(data = pixel_1a, distribution = "discrete", pixelGeo = pix_a, id = "my_id", border = pixel_2a, q=q_a)

p4a <- view(pmap_a) +
  geom_path(
      data = pmap_a$bord,
      aes_string(x = 'long', y = 'lat', group = 'group'),
      colour = "white"
    )  +
  scale_fill_gradientn(colours = basecols) +
  scale_colour_gradientn(colours = basecols) +
  theme(legend.position="none")

# High variance
my_map_data_b <- my_map_data %>%
  filter(variance_class == "highvar") %>%
  mutate(my_id = seq(n),
         error = variance) 

q_b <- my_map_data_b |> 
  as.tibble() |>
  mutate(bitemp=as.numeric(bitemp)) |>
  with(data.frame(p0.05 = qnorm(0.05, mean=bitemp, sd=sqrt(variance)),
                  p0.25 = qnorm(0.25, mean=bitemp, sd=sqrt(variance)), 
                  p0.5 = qnorm(0.5, mean=bitemp, sd=sqrt(variance)), 
                  p0.75 = qnorm(0.75, mean=bitemp, sd=sqrt(variance)), 
                  p0.95 = qnorm(0.95, mean=bitemp, sd=sqrt(variance))))|>
  apply(2, function(x) ifelse(x>8, 8, x)) |> #this will mess with the variance
  apply(2, function(x) ifelse(x<0, 0, x))

pixel_1b <- my_map_data_b %>%
  as.data.frame() %>%
  select(my_id, bitemp, error) %>%
  read.uv(estimate="bitemp", error="error")

pixel_2b <- my_map_data_b %>% 
  as("Spatial")

pix_b <- pixelate(pixel_2b, pixelSize = 3, id = "my_id")

  
pmap_b <- build_pmap(data = pixel_1b, distribution = "discrete", pixelGeo = pix_b, id = "my_id", border = pixel_2b, q=q_b)

p4b <- view(pmap_b) +
  geom_path(
      data = pmap_b$bord,
      aes_string(x = 'long', y = 'lat', group = 'group'),
      colour = "white"
    )  +
  scale_fill_gradientn(colours = basecols) +
  scale_colour_gradientn(colours = basecols) +
  theme(legend.position="none")


  
# Display plots and palettes
p4a
p4b
show_pal(basecols, ncol=8, borders="white", myxlab = "Temperature", breaks = 21:29)
```

It is clear that the pixel-map is not only "suppressing" the false information, but it is doing so by simulating *more* information. The efficacy of this method means that visualisations of simulated samples pop up repeatedly in the literature, with examples including samples that are animated over time [@Hullman2015; @Blenkinsop2000], pixel-maps, and spaghetti time series plots. Not only does this method help readers understand the plot level "gist", it is also unlikely to damage the viewers ability to extract individual estimates. Extracting global statistics, such as the mean or variance, from a sample can be done with relative each, especially when those values are mapped to color [@Franconeri2021]. Therefore, the pixel map performs signal suppression, without sacrificing the viewers ability to extract general statistics, unless those statistics *should* be harder to extract due to the uncertainty in the value. So is this the best uncertainty visualisation? And if so, why?

## Show me the data
The pixel map is not the best uncertainty visualisation, but it is trying to *imitate* the best uncertainty visualisation. The best uncertainty visualisation is the visualisation that best captures the limitations of of our raw data.  As we discussed in previous sections, we can consider uncertainty to be "the amalgamations of the impacts of violations to the assumption of the uniformity of nature". It's not a definition that rolls off the tongue, but we can work with it.

Thankfully, this definition of uncertainty aligns nicely with all the concepts that are included in the uncertainty umbrella. Some works [@Hullman2018; @Maceachren2012; @Thomson2005] focus narrowly on specific terms with mathematical definitions, such as probability, confidence intervals, variance, error, or precision. These works are only concerned with quantifying the final impact of uncertainty on our statistics. That is, how large should the bound around our statistic be, such that our "true" statistic can be inferred. Others [@Griethe2006; @Leland2005; @Pang1997; @Pham2009; @Boukhelifa2017] include broader loosely related elements, such as missing values, reliability, model validity, or source integrity. These broader and harder to quantify concepts are concerned about potential sources of uncertainty, that is, they describe violations to the assumption of the uniformity of nature. 

What this means is that we have two types of uncertainty, but one is more "processed" than the other. Quantifiable uncertainties are just assumption violations expressed as an effect on our final statistic. The disconnect between these two expressions of uncertainty creates a huge problem for authors trying to visualise it. A survey of visualisation authors cited "not knowing how to calculate uncertainty" as one of the primary reasons they did not include it in visualisations [@Hullman2020a]. 

There are two reasons we might leave our uncertainty as an assumption violation rather quantifying the effect. The first reason is that we may be unable to translate the assumption violation to a quantifiable uncertainty. There is no blanket rule that allows us to reliably quantify all uncertainty for every statistic, although some researchers have tangled with the idea. For example, @Thomson2005 suggests a mathematical formula for *examples* of uncertainty, and information theory tries to quantify uncertainty using the idea of entropy, but they ignore the disconnect between the broad concept of uncertainty and what we can reliably quantify. Some authors don't believe that it is even possible to quantify all the assumption violations. @Spiegelhalter2017 mentioned that combining the uncertainties that appear at each stage of an analysis into a single "uncertainty" value is near impossible. 

The second reason to leave uncertainty as a potential violation of our assumptions, is that we might not know the final statistic we are seeking to calculate. This is the case for visualisations made for EDA, and a large number of developments in EDA visualisation have been in displaying these difficult to quantify violations. For example, @Tierney2023 builds upon the tidy data principles to allow users to handle missing values. This includes data plots with a missing value "shadow" that allows visualisation authors to identify if the variables used in a plot have any structure in their missing values, which would contribute to uncertainty.

With this understanding it becomes clear to see why uncertainty is tied to an endless string of examples in the data analysis pipeline. Uncertainty examples include imputed data, model selection, inherent randomness, biased sampling, etc, not because these things *are* uncertainty, but because they *create* uncertainty when we perform inference. Whether or not these elements are relevant is highly dependent on what statistic you are trying to draw inference on, and by extension, the purpose of your visualisation.

This relationship between uncertainty and the "purpose" of our analysis is littered throughout the literature. Multiple authors have commented on the need to consider quantifying and expressing uncertainty at every stage of a project as the "goal" shapes every step of the analysis [@Kinkeldey2014; @Hullman2016; @Refsgaard2007]. @Otsuka2023 suggested that the process of observing data to perform statistics is largely dependent on our goals, because the process of boiling real world entities down into probabilistic objects (or "probabilistic kind" as he puts it) depends on the relationship we seek to identify with our data. @Meng2014 commented what is kept as data and what is tossed away is determined by the motivation of an analysis and what was previously noise can be shown to become signal depending on the the question we seek to answer.  @Wallsten1997 argue that the best method for evaluating or combining subjective probabilities depends on the uncertainty the decision maker wants to represent and why it matters. @Fischhoff2014 looks at uncertainty visualisation for decision making decides that we should have different ways of communicating uncertainty based off what the user is supposed to do with it.  

This makes it very difficult to move quantified uncertainty through the the layers of our analysis, especially when designing a visualisation for EDA. If we don't know what the final statistic is, we cannot quantify the effects of our assumptions. Therefore, often the best uncertainty visualisation is not an "uncertainty visualisation" at all, but simply the most accurate depiction of our raw data as it gives us a good idea of it's limitations. 

This does not mean that visualizing raw data instead of implementing sampling techniques will always prevent insignificant signal from getting through. @Buja2009 illustrated how groups that appear linearly separable in a linear discriminant analysis (LDA) visualisation of the data can actually be the result of a LDA performed on too many variables, something that was not clear from the visualisation until the line-up protocol was implemented. However just showing the data it is simple but effective option for uncertainty visualisation that that seems to be largely overlooked. While it is not always possible, it should always be considered as an effective uncertainty visualisation when the raw data is available.


{{< pagebreak >}}

# Evaluating uncertainty visualisations
If we want to make conclusions about how effective any uncertainty visualisation method is we need to look at the results of evaluation experiments. Unfortunately the illustrative methods we have used thus far, i.e. showing a graphic and saying "wow look at this", are lacking if we want any generalizable results. However, despite the abundance of uncertainty visualisation evaluation experiments, existing literature reviews have struggled to synthesise them into any common rules [@Kinkeldey2014; @Hullman2016]. 

Here we discuss common evaluation methods, why these methods might struggle to create a cohesive set of recommendations for uncertainty visualisations, and consier how we to best evaluate visualisations on their ability to perform signal-suppression.

## Current methods
Including uncertainty in a visualisation comes with many secondary benefits. Examples of these benefits include better decisions, more trust in the results and the ability to extract additional statistics, such as the variance. Ultimately, these secondary benefits are not the primary goal of uncertainty visualisation, and evaluating uncertainty visualisations on these criteria often has unintended consequences. 

### Value extraction of uncertainty statistics
Uncertainty visualisations are often evaluated based on how accurately [@Hullman2019] viewers can separately extract the estimate and the variance [@Kinkeldey2014]. This means a significant chunk of evaluation studies boil down to showing a participant a visualisation and asking questions such as "what is the variance of $X$?", or "what is the mean of $X$?". This seems like a relatively straight forward approach, and it is similar to how non-uncertainty visualisations are evaluated, but is this appropriate for uncertainty visualisations? The role of uncertainty is rarely evaluated in these studies as the graphics are often compared on the basis of being "uncertainty visualisations" [@Ibrekk1987; @Hullman2015; @Hofman2020], a class that has no established definition. By shifting the focus of our inference from $\bar{X}$ to $Var(X)$ or $P(X)$ we end up evaluating visualisations on their ability to convey uncertainty statistics, rather than on uncertainties ability to suppress statistics. This leads to a series of experiments where the uncertainty is evaluated as a signal even if that was not the goal of the experiment.

The problem with evaluating uncertainty as a signal are identical to the problems associated with displaying uncertainty as a signal. There is no reason to assume uncertainty would behave any differently to any other variable when we evaluate them in this way. For example, @Ibrekk1987 found that participants were more accurate at extracting a statistic when it could be directly read off the graphic, than when it required an area estimate (which is the case if using the PDF), or when there was no visual indicator for the statistic at all (which is the case when using the CDF of an asymmetric function). @Hullman2015 found that a visualisation that allows viewers to count outcomes to estimate a probability outperformed one that required a complicated area calculation. @Hofman2020 and @Zhang2022 found that participants were better at answering questions about a prediction intervals when shown a prediction interval instead of a sampling distribution. @Gschwandtnei2016 found that graphics where the required statistic could be directly read off the plot outperformed those that involved guesswork due to a gradually decreasing line. @Cheong2016 found that participants made better decisions when they were explicitly given the relevant probability in text rather than when they needed to read it off a map. It is well established that extracting information from a graphic using a perceptual task will always be less accurate than explicitly reading the value provided in text form [@Cleveland1984].

The biggest failing of this evaluation method is not the predictable outcomes, but that it encourages us to see successful examples of signal-suppression as a failing. @Blenkinsop2000 commented that visually integrable depictions of uncertainty should be avoided, as they decrease the viewers confidence in their extracted data values. This conclusion is antithetical to the goals of signal-suppression and occurs because these methods evaluate uncertainty as a signal, not as noise. 

### Trust, confidence, and risk aversion
Trust is a by-product of displaying uncertainty and it commonly measured in uncertainty evaluation studies [@Hullman2019]. Considering trust, and not transparency, as the metric of importance in uncertainty communication can lead to a questionable subtext that argues against transparency, something that has been noticed by several other authors [@Spiegelhalter2017; ONeill2018]. Science communication should be primarily concerned with accuracy. 

Setting trust as the variable of interest implicitly encourages statisticians to set trust and as the primary goal of communication. Evaluating visualisations on trust conflates trust and transparency and ultimately discourages signal-suppression. We can see this effect pop up in the results of evaluation studies. For example, @Zhao2023 found that participants were more trusting of model estimates with low uncertainty, but this effect did not carry over to estimates with high uncertainty. Despite decreased trust being a desired outcome of signal suppression, the authors discussion implied this result was not desired. This perspective ends up extending to visualisation authors as well. @Hullman2020a found that author simultaneously argued that failing to visualise uncertainty was akin to fraud, but also many avoided uncertainty visualisation because they didn't want their work to come across as "untrustworthy". This is a classic example of the negative impacts of placing direct importance on *trust* rather than *transparency*. In cases of high uncertainty, authors will opt to leave out uncertainty information because it decreases confidence in the authors conclusions. This is the end result of designing uncertainty visualisations for increased trust, rather than signal-suppression.

Another metric that is similar to trust is the participants confidence in their decision or extracted value. Confidence has many of the same issues as trust, but it has an additional confounding factor. In non-uncertainty visualisation evaluation experiments, "confidence" is used as a proxy for the clarity of the visualisation. Confidence cannot simultaneously be a measure of clarity of visualisation *and* a way to capture the uncertainty expressed in a visualisation. Uncertainty visualisations conflate these two measures when they ask about confidence.

Risk-aversion is another secondary effect of uncertainty visualization that is used to evaluate uncertainty visualisations [@Hullman2019]. Risk aversion is an economics term used to describe an agent who would chose a random variable with a lower expected payout because it also has a lower variance. Risk aversion is considered irrational behaviour because it is a deviation from the behavior of a rational agent. Comparing participant responses to that of a ration agent has even been suggested as a benchmark for uncertainty visualization experiments [@wu2023rational]. However, just like trust, evaluating graphics on risk-aversion discourages signal-suppression. Rational agents *by definition* should *ignore* uncertainty information. Risk aversion is considered to be irrational because it means the economic agent *is* considering the uncertainty information. The only cases where a rational agent should not ignore the uncertainty information is when the uncertainty is signal, not noise. Designing graphics that encourage choices that align with that of a rational agent, is to encourage graphics that do not include uncertainty at all.

For these reasons we do not believe trust, confidence, or risk-aversion are useful measures to evaluate uncertainty visualisations. While they are designed to capture the secondary effects of uncertainty, using them as primary measures of visualisation performance is in direct conflict with designing visualisations for signal-suppression.

### Questions that attempts to capture signal-suppression
There is a collection of studies that seem to be aware of the issues behind using trust or value extraction to evaluate uncertainty visualisations. These studies try to measure the effect of some kind of "single integrated value" but the methodology is often ad-hoc with varying levels of success. 

The first method is what we call the "vague question" approach. The authors of these studies will ask the participants a question that implies that they should use  a use of uncertainty, but compare the readers answer to a very specific ground truth. This means the participants are being *evaluated* as though they are performing a value extraction task, but they are not being asked the *questions* that are asked in the value extraction task. Ultimately this approach results in strangely cryptic questions that create a large amount of noise due to the varied interpretation of the questions [@Hullman2016]. For example @Hofmann2012 showed study participants 20 plots, where each plot displayed two distributiosn (as a pair of jittered samples, density plots, histograms, or box plots) and asked them to identify the plot where "the blue group furthest to the right". The mean of the two groups was used to decide which group was actually "furthest to the right" and the participants were evaluated against that ground truth. In another example @Ibrekk1987 asked participants for the "best estimate", but the participant's responses were evaluated against the mean of the distribution. Ultimately, the term "best" is up to the users interpretation, and the estimate that minimized the sum of squared errors was not implied by the question. This vague question approach leads to inconclusive results, as we are left unclear if it was the phrasing of the question or the plot design that caused the participants to answer incorrectly.

A variation of the "vague question" problem, is a series of studies that ask questions that are impossible to answer using the information given to the participants. These studies frequently expect participants to give deterministic answers for probabilistic questions. For example @Correll2014 showed participants the distribution of voter preferences for two candidates in an election, and aksed them "how likely is candidate B to win the election?". Participants were not able to answer the question about likelihood in term of probability, but were instead given seven options from 1 = "Outcome will be most in favour of A" to 7 = "Outcome will be most in favour of B". The ground truth statistic for this question was a scalar multiple of Cohen’s d, indicating participants were supposed to incorporate uncertainty information using a very specific formula that was likely unknown to them but assumed to be used implicitly.  In another example, @Padilla2017 provided participants with a visualisation of the cone of uncertainty and asked then to "decide which oil rig will receive more damage based on the depicted forecast of the hurricane path". The cone of uncertainty provides a 60% confidence interval for the location of the eye of a hurricane, which allows us to know the area where the eye of the storm will go, it does not given any information about the intensity of a storm, the size of a storm, or even if a location will be hit. Other authors have commented on the complexity of communicating hurricane risk because the path, storm surge and wind speed are all important and cannot be ignored [@Spiegelhalter2017]. Interestingly it is unclear how the participants were supposed to answer this question, as @Padilla2017 did three experiments and the first and third experiment had conflicting assumptions in their ground truth. In the first study, participants were required assume to the storm was equally intense reguardless of the probability of the probability of the oil rig being hit (i.e. more likely to be hit *does not* mean more damage) but in the second study required participants to assume the opposite (i.e. more likely to be hit *does* mean more damage). Similar to the vague question problem, these studies seem to be aware that we should be evaluating an uncertainty visualization based on a deterministic observation (such as our example of "does this map have a spatial trend") but are unsure how to incorporate or evaluate it. 

While these approaches are certainly a step in the right direction, the experiments end up having far too much noise in their results. Additionally, by having a ground truth, they end up implicitly asking users to either treat uncertainty as a signal, or to ignore it entirely, neither of which is advisable for evaluating graphics on signal-suppression. 

## Testing signal supression
If we cannot ask direct questions about uncertainty, we cant measure the secondary effects of uncertainty, and we can't ask indirect questions about the uncertainty, how are we supposed to evaluate uncertainty visualisations? How do you measure something that disappears the second you look directly at it? To evaluate uncertainty visualisations, we need an experimental design that evaluates uncertainty as noise, not as signal. This means we need to measure *uncertainty's impact on the signal*, not the uncertainty itself.  

### Comparing to hypothesis tests
The most obvious way to evaluate uncertainty visualizations is to compare the visualisations to statistical tests. If a graphic was performing signal-suppression we would expect the signal to be harder to see at higher levels of uncertainty. The ideal outcome is a an uncertainty visualisation where the signal is only perceivable when it would be identified by a hypothesis test. Evaluating visualisations as though they are akin to hypothesis tests is a well established concept in visualisation. The lineup protocol is a good example of this approach, which is a confirmatory visualisation tool that can be used to check if perceived patterns are real or merely the result of chance [@Buja2009; @Wickham2010]. The motivation behind the lineup protocol is similar to the motivations behind signal-suppression, although the lineup protocol is more explicitly tied to a specific hypothesis. @Patrick2023 compared standard statistical tests to the lineup-protocol, and evaluated the visualisations using the power curves that are typical for hypothesis testing. In a similar vein, @Kim2019 investigated how different uncertainty visualisation methods influenced user's prior beliefs, and evaluated the graphics by comparing their results to those from Bayesian inference. This approach is similar to the lineup protocol as it also evaluates a visualisation by comparing it to an analogous statistical calculation, however it does so using a different statistical philosophy. 

We can use a similar evaluation method to evaluate uncertainty visualisations, however, special care would need to be taken for their versatility requirement. While lineup protocols often have a specific hypothesis that is used to create the null distribution, uncertainty visualisations are intended to be more flexible and can be created without visualizing a specific null distribution. Human viewers using the lineup protocol are less sensitive to deviations from the null hypothesis than the typical statistical tests [@Patrick2023]. This means swapping to a visual format and giving viewers the ability to check several hypothesis at once can reduce the effectiveness of the hypothesis test. Therefore it is highly likely that uncertainty visualisations would not produce identical results to standard hypothesis tests or even the lineup-protocol. Additionally, uncertainty visualisations would need to be simultaneously checked against several hypothesis that come from a variety of null distributions.  

### Qualitative Studies
Alternatively visualisation research could shift away from the accuracy concept all together ask questions that allow for open ended responses. This method can enlighten authors as to *how* the uncertainty information was used by the participants. @Hofmann2012 tried to capture this by asking participants why they considered a particular plot to be more "right shifted", even though this qualitative analysis did not make it into the final paper. @Daradkeh2015 presented participants with ten investment alternatives and asked participants "from among available alternatives, which alternative do you prefer the most", and were asked to think aloud and consider the uncertainty in their decision making. The experimenters goal was to observe and organise the methods people use when making decisions in the face of uncertainty. They highlighted the specific aspects of uncertainty that participants typically considered, such as the range of outcomes that are above/below a certain threshold, minimum and maximum values, the risk of a loss, etc, and identified where in the decision making process participants made these considerations. 

### Heuristics
While experiments that explicitly identify heuristics in current methods are not technically measuring signal-suppression, they are still a useful consideration to keep in mind when designing experiments for signal suppression. Heuristic checks are look at unknown pitfalls that might exist in interpretation of current plots [@Hullman2016] and can change depending on the larger scope of the graphic and the population we are communicating with [@Spiegelhalter2017; @Kinkeldey2014]. 

Several heuristics are of particular importance for uncertainty visualisations, and are likely to impact how well different methods performing signal suppression. The sine illusion can cause the confidence interval of a smoothed sine curve to seem wider at the peaks than the troughs, causing us to underestimate uncertainty associated with changing values [@Vanderplas2015]. Points that were on an outcome of an ensemble display were perceived as more likely than points not on an outcome, even when the point that was not on an outcome was closer to the center of the distribution (and therefore more likely) [@Padilla2017]. This can be considered an extension of the within bar bias, where participants looking at a bar chat with error bars view outcomes within the bar as more likely than those outside it [@Newman2012]. Several studies have found that viewers use a heuristic where they compare the distance between two estimates to estimate if they are different, and in doing so, ignore the uncertainty information [@uncertchap2022].

These heuristics have the potential to create noise in signal suppression evaluations, and should be kept in mind when designing an evaluation experiment.


{{< pagebreak >}}

# Future work
This paper has identified gaps in the uncertainty visualisation literature that could be filled to progress the field.

*Each new development should be accompanied by a mathematical definition of the uncertainty being addressed.* Ideally, a mathematically definition of uncertainty that allows us to combine these components would be developed, but in the absence of that, authors should be more specific about what aspect of "uncertainty" they are covering with their visualisation.

*The concept of uncertainty should be formalised within the grammar of graphics.* This formalisation would allow uncertainty visualisation authors to have a clear understanding of what is or is not an uncertainty visualisation. Additionally placing uncertainty visualisation in the framework that is used to understand existing information visualisation research would help authors understand when existing methods can be used to explain their results. incorporating uncertainty into the grammar of graphics will also give a more precise concept of the information contained within a plot. Other fields of science employ marginal changes when designing experiments to ensure it is well understood *what* aspect of their experiment is contributing to their results, and a better sense of what "marginal" is in the case of uncertainty visualisation would greatly help the field. (*XXX Is data pipeline connected with the grammar of graphics? Should this be a recommendation?*)

*Experimental practices on uncertainty visualisation need to be standardised.* If we are going to consider uncertainty as noise, not signal, there needs to be a way to identify this signal suppression in an experimental design. As the literature currently exists, there is no way to combine papers to get a meaningful sense of how uncertainty information is understood by a viewer. There is also the possibility that uncertainty visualisation evaluations will need to swap to a qualitative methodology where participants are allowed to freely comment on what they notice in graphics until we establish how the existence of noise can be observed.

If an uncertainty visualisation researcher would prefer to perform experiments rather than formalise methods, there are options there too. It would be interesting to know if any perceptual tasks that can be mapped to two different visual tasks condense into a single dimension when looking for overarching signal in a plot. Alternatively, the task dependency many authors in uncertainty visualisation mention would be a useful direction to consider. It is clear that the the number of potential tasks that can be performed on a visualisation increases with with the number of observations. A single observation is limited to value extraction, two observations can be compared, multiple observations allow for shapes or global statistics to be extracted. The interaction between sample size and task is of particular interest to the uncertainty visualisation community, as uncertainty can be expressed through multiple observations using a sample, or through a single value using an error. Of course, this is limited by the fact that there also isn't a definition for what is a "task" and given the mess created by the lack of formalisation in uncertainty visualisation, it may be wise to formalise that concept before performing these experiments. @Amar2005 suggested a taxonomy for information visualisation based on the types of tasks we use visualisations for and suggest 10 "analytical primitives" that we can then map to visualisations, which could be a good starting point. Regardless, these are directions of research would be fruitful to the uncertainty visualisation community even if it appears on the surface to be research that is only beneficial to the "normal" visualisation community. (*XXX Not sure what this paragraph is recommending?*)

# Bibliography

```{r, include=FALSE, eval=FALSE}
library(spelling)
qmd <- "paper.qmd"
ignore <- readLines("WORDLIST")
check_spelling <- spell_check_files(
  qmd,
  ignore = ignore,
  lang = "en_GB"
)
if (nrow(check_spelling) > 0) {
  print(check_spelling)
  stop("Check spelling in Qmd files!")
}
```






