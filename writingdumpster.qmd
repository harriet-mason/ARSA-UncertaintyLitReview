---
title: "Writing Trash Bin"
author: "Harriet Mason"
format: html
---
# Why this exists
I have an information hoarding problem, this helps me throw out sections of the literature review that are not necessarily relevant without actually throwing it out. Knowing that I can come back to this at any point and pull information back, makes me more comfortable with removing it from the report.

# Moved over notes
- @Bella2005 found that most participants were ignorant to the fact that error bars are used for both confidence intervals and standard error bars, two wildly different indicators of precision. (**also the paper sherry sent me**)
- Several studies probide evidence that the usability of uncertainty representations can be highly user and task dependent @Kinkeldey2014
- The tasks for participants were most commonly value retrival (some where uncertainty and data value are retrived separately, others where they are some separately). also also be asked to extract a relative value @Kinkeldey2014
- most studies used coincident approaches, static visualisations, are applied to a specific domain and dont have generalised results @Kinkeldey2014
- Most studies involve intrinsic approaches such as colour, transparency, and those that used extrinsic techniques typically used glyphs, error bars, grid based techniques, or contouring @Kinkeldey2014
- Mentioned alleatory vs epistemic uncertainty, in the visualisation literature alleatory uncertainty is more commonly the focus. also mentions dependence and joint pdfs as a consideration @Hullman2016
- When asking questions, researchers should focus on events that can be repeated (because of a misunderstanding of confidence intervals) @Hullman2016 (moved here because it is clear she is touching on the whole "what are we uncertain about" thing)
- we should aim to show enough information to solve a task while avoiding irrelevant distracting information [@kosslyn2006graph]. 
- people will discount information they perceive as discountable if they are able. Including mean estimates on depictions of mass can cause people to discount the uncertainty information and use the difference between means as a proxy for the probability distribution [@Kale2021].
- rarely used extension is aggregation of uncertainty over an area (retrieve overall estimation from a spatial distribution of uncertainty). Other tasks include comparisons, rankings. also have a task called "search" where participants have to identify entities that fulfill certainty characteristics (high or low values) @Kinkeldey2014
- Whether to use classed or unclassed uncertainty is rarely discussed @Kinkeldey2014. e.g. land map with remotely sensed images has ambiguity in the boundaries, which can result from multiple sources (land cover class, measurement error, images from different dates). If you combine them all it might not make sense for someone who only needs one.
- The way we ask questions and the types of questions we ask are selected with little justification. This paper makes suggestions to reduce the noise in the data from these papers. @Hullman2016
- Error is best mapped to fuzziness, location, and colour value; arrangement, size and transparency are an OK second choice; but saturation, hue, orientation and shape are unacceptable and have no intuitive connection to variance [@Maceachren2012]. 
- @Nathonours found that a scatter plot is better than a line plot if you want to convey the correlation between two time series but we cannot be sure if this was influenced by swapping the distribution depicted or by dropping the irrelevant feature of inexchangeability.
- No only do the graphical elements we map our features to matter, but the direction matters too. Graphical elements that are more fuzzy (fuzziness), further from centre (location), lighter (colour value), poorly arranged (arrangement), smaller (size), more transparent (transparency) are perceived to be more uncertain [@Maceachren2012]. 
- This idea also extends to interval estimation, where questions about probability are best answered with gradients and questions about start and end times are easiest to answer with ambiguation [@Gschwandtnei2016].
- Heuristics can work against us just as much as they can work for us. The sine illusion can cause the confidence interval of a smoothed sine curve to seem wider at the peaks than the troughs, causing us to underestimate uncertainty associated with changing values [@Vanderplas2015]
- mentions uncertainty can be variance, precision, accuracy, reliability, or related concepts @Hullman2016
-  @Spiegelhalter2017 defines risk as risk known probabilities and uncertainty as estimated probabilities, therefore uncertainty is what we have when you cannot accurately quantify risk.
- Authors provide little justification for their chosen response models (e.g. absolute accuracy vs relative measures) @Hullman2016 
- Some questions (e.g. what are the chances that the no.6 bus will arrive first) you can elicit the viewers subjective probability distribution @Hullman2016
- The big data paradox shrinks confidence intervals but magnifies bias [@Bradley2021] because the confidence intervals shrink due to the sample size but the imprecise target group creates bias.
- coloured maps for earthquake risk are easily interpretable @Spiegelhalter2017
- Hurricane risk is not only the path, but also the storm surge and wind speed. @Spiegelhalter2017

# Experiment paper checklist
General
- Specific Field of Research
- Question asked
- Risk or Uncertainty: 
- Noise vs signal (risk vs uncertainty)
- Major task goal
    - e.g. identify a bias or misunderstanding, compare two visualisation methods
- Minor task goal
    - Communication(value retrieval)
    - Analytical(complex consideration)
    - Exploration(free for all)

Uncertainty Considerations
	- Source
	- Level (statistical-ignorance)
	- Nature (Epistemic/Aleatory)

Visual Uncertainty taxonomy
- Explicit/implicit
    - (directly mapping or showing multiple outcomes)
- Intrinsic/Extrinsic 
    - (using existing symbols e.g. colour value, or new objects e.g. grids)
- Visually integral/separable 
    - (can or cannot be separated from the data) 
- Coincidence/adjacent 
    - (if data and uncertainty are in integrated or separate views
- Static/dynamic 
    - (animation/interaction) 

Other plot considerations
	- Dimension of data
	- Dimension of uncertainty
	- Feature mappings

Extra (not necessarily recorded)
	- Metrics used (and recorded)
	- Possible Heuristics
	- What is the ground truth?
	- Participant literacy

 

# Main section outtakes
- tasks e.g. "What is the average of X" (how well lined up you are moving down the data pipeline) and resolution (uncertainty is very often moving back a resolution level in statisitcs - also can be an assumption - bootstrap is a replacement for an assumption, not a resolution change, but bootstrapping is centered on the data)  e.g. "What is the noise around the estimate of the value of X"
Visualisation experiments are highly sensitive to the way questions are asked. For example, a study by @Hullman2015 that compared HOPs, error bar, and violin plots found that many participants reported that group A was more likely to be higher than group B, which was not not plausible given that the mean of B was larger than the mean of A. The authors attributed this obvious mistake to the visual representation, but we believe it was more likely caused by the distributions being shown in the order A then B while the question swapped the order by asking "What is P(B>A)?". This flip is minor, but must be done *after* the participants have worked out the probability. Since the primary task is done they forget to complete the secondary task, similar to forgetting your bank card in an ATM. I suspect this was the cause of the mistake as I, when attempting this question myself, made the exact same mistake. I also constalty lead my bank card in ATMs.

While mathematical information *should* be considered the starting point in considering if two visualisations are equivalent, it is not the only consideration. A large amount of work in perceptual tasks, attention, and psychology surrounding charts shows that all the information depicted is not paid attention to in equal measure. Elements such as colour can have sizable impacts on the way a graphic is percieved. Mathematics identifies the information that is *shown* while psychology identifies the difference in information *recieved*. A failure to understand this distinction leads to graphics that are different not only in the way information is depicted but in the information itself. This problem is pervasive in uncertainty visualisation literature.

This is not to say any paper that discusses uncertainty visualisation is completely pointless because the results already exist. We are simply pointing out that treating uncertainty graphics as special simply because they contain uncertainty, even if that uncertainty is not related to the task, leads to results that are already established in information visualisation.

These two perceptualisations of *why* uncertainty visualisation is different from normal visualisation is also what leads to differing opinions on what is an uncertainty visualisation. For example, someone who percieves of uncertainty visualisation as a dimensionality problem would see a pie chart as a normal graphic, and a pie chart with blurred boundaries as an uncertainty visualisation (even though blurring the boundary between segments of a pie chart makes no sense when you think of a pie chart as a polar co-ordinate bar chart), while someone who sees uncertainty visualisation as psychologically different would see a pie chart as an uncertainty graphic so long as it depicts probabilities. This may lead you to believe that those who believe uncertainty is unique due to its psychological properties believe uncertainty should be defined at the mathematical stage, while those that believe it is an addition to an established visualisation think uncertainty is defined in a graphic at the aesthetic stage. This is not the case. As shown by the *grammar of graphics fig* there is no single person or experiment that is consistent in any one belief. This difficulty and lack of consistency comes from the desire to discuss "uncertainty visualisation" as though it is a single term and not the combination of "uncertainty" and "visualisation". If we split the terms and look at the quantification and visualisation of uncertainty separately, the results of many uncertainty visualisation papers become self evident. 

Papers that are justified using the first type of motivation rarely explain exactly how the psychological apsects of uncertainty impct the participants in a way that inhibits their ability to read information from a graphic. Since uncertainty is poorly defined and the psychological effects of uncertainty is never justifiably connected to the scientific communication of it, as was discussed in ssections 3 and 4, it is unclear exactly *what* these papers are testing for. It is almost as though they *feel* that uncertainty visualisations *should* be different, but do not consider *how* uncertainty information is supposedly different beyond decision making criteria such as *risk avoidance* which is not something science communicators have any business trying to control, as was discussed in previous sections. For these reasons, experiments that test for secondary factors (such as influence on decision making) are confounding far too many variables to establish any generalisiable take away, and experiments that ask participants to extract values fail to notice there is no longer a reason for "uncertainty" to be any different to any other type of visualisation. 

Papers that are justified using the second type of motivation clearly fit within the sub-field of high dimensional visualisation, but also rarely comment on the connection. These experiments evaluate different ways to include even *more* information than would be put in a typical visualisation. Some of these methods, such as a bivariate pallet or glyph map, create graphics that are overloaded with information and offer incorrect or meaningless takeaways at first glance. This is not to say *every* visualisation method that sees it as a dimensionality problem is bad. Clever methods of combining several types of information, such as value supressing uncertainty pallets (VSUPs), can better help us understand how our brains process information in a graphic.  For example, the VSUP allows us to test is colour value and saturation can be combined such that we mentally combine signal and noise together as one variable. Since the take aways from the papers are not usually related to uncertainty specifically, and often related to interesting perceptual tasks, there is also no justification for why this work is "uncertainty visualisation" work and not simply perceptual task studies that can be used by the rest of the information visualisation community.

This stems from a class of "uncertainty visualisation" that seems to have no rules for what belongs in the group, and no consideration for the mathematics that is actually depicted in these plots. Uncertainty visualisation experiments do not work to build upon existing visualisation literature or differentiate uncertainty visualisaiton as a new field, but seem to exist with shocking indifference to the field it belongs to. 

uncertainty visualisation, as it is now, should not exist. Any generalisable contribution made by these papers is already an established result in information visualisaiton, and therefore is not specific to "uncertainty visualisation".  Any "uncertainty visualisation" specific result is not generalisable beyond the experimental conditions because of the poor formalisation in the definitions of uncertainty and uncertainty visualisations.

This lack of formalisation is not unique to uncertainty visualisation and the wider field of information visualisation suffers form similar problems [@Kinkeldey2014].

This makes it clear we have a serious problem with the classification of "uncertainty visualisation". The visualisations follow identical rules to those established already in the visualisation literature, and experiments that view uncertianty visualisation as somehow special or different from normal visualisation are simply repeating existing established research in information visualisation. 

If several graphics are compared that are different statistically, geometrically, and aesthetically, there is *no way to combine the results to establish generic principles for the field*. 

The overwhelming majority of these papers depict different mathematical expressions of both the signal and the uncertainty. In 100% of these papers, the plot that has mapped the statistic in question to some visual feature will outperform those that don't. When the statistics used to depict uncertainty *are* the same (which is rare) 100% of those papers will follow the hierarchy of perceptual tasks that has already been established in the visualisation literature. If the experiment participant needs to extract a probability and one graphic uses position along a common scale, while the other uses colour or literally any other perceptual task, the position depiction will always outperform the other.

If we were to compare two different visualisations, we would like to change as few features as possible so we can better understand the cause of the difference in perception.  

Additionally, if information that can be used to calculate a statistic, but not the statistic itself, is shown, people will need to use a heuristic to extract that information which will decrease the precision with which that information is communicated. If the information that is depicted on a plot cannot be used to *mathematically* generate a best estimate for a specific statistic, it is questionable how uncertainty visualisation authors expect participants to cover that gap if *not* for heuristics.

In these papers will typically ask separate questions about the signal (e.g. what is the mean of this distribution) and the uncertainty (e.g. what is the variance of this distribution).

Failling to understand this key aspect of visualsiation leads to graphics that *contain* the correct amount of information, but that volume of information cannot be readily accessed by the viewer.

## Taxonomies
Some taxonomies contain overlapping terminology but also have alternative definitions and categories. For example *___* organises uncertainty into the two categories, Aleatroy (inherrent randomness) and epistemic (lack of knowledge), but *___* organises uncertainty into the three categories aleatory (inherrent randomness in a forecast) vs epistemic (uncertainty in structure and parameters of statistical models) vs ontological (uncertainty about the entire modelling process as a description of reality). 

To avoid alienating lay people with confusing complexity, many of these taxonomies are overly simplistic. Most taxonomies seek to organise uncertainty based off where the uncertainty is coming from. For example, @Spiegelhalter2017 organises uncertainty into three categories: 
  - Aleatory uncertainty: inevitable unpredictability due to unforeseeable factors 
  - Epistemic uncertainty: uncertainty about the structure and parameters of statistical models
  - Ontological uncertainty: uncertainty about the entire modelling process as a description of reality.
These three categories can be considered to be uncertainty when deciding which model we should use (ontological), uncertainty surrounding parameter estimates (epistemic), and uncertainty surrounding a forecast (aleatory), however it is not hard to find another, very different, example of a taxonomy that organises uncertainty based on what is seen to be causing it. @Gustafson2019 organises uncertainty into the four groups:
  - Deficient: Lack of knowledge
  – Technical: modelling approximations and measurement error
  – Scientific Unknown unknowns
  – Consensus: Disagreement among parties
However the additional comments about the inherent variability of aleatory uncertainty results in a bit of confusion as to if our cateogirisation should change if we decide to treat the parameters of a statistical model to be inherently random (as is done in Bayesian statistics) or if we beleive a forecast variability to be caused by a lack of knowledge.

He kept the taxonomy to three levels to maintain simplicity, however this organisation methods conflates amount of uncertainty present in an estimate with what is causing that uncertainty, and in doing so makes it hard for us to use this definition to better understand uncertainty within our own analysis.
# context section outtakes
Given that uncertainty estimation and communication seem to be largely task depenent, what questions should we be testing? This leads to several unanswered questions. Is our goal in uncertainty communication to acknowledge and convey the inherrent randomness that exists in all statistical calculations and models? Is it to supress signal that could be the result of random variance? Is it to find the best way to convey the mass function of a random variable? A survey of the literature will leave the answers to these questions unclear, however this inherrent issue has not gone unnoticed.
This conceptual way of thinking about uncertainty has been rattling around in the different areas of data science for a while.
For example, when we record coin flips we typically want to model the behavior with a binomial distribution, so we ignore the outcome of a coin landing on its side despite the fact it is a real world possibility.


# General Thoughts For Actual Review
##### General
- I might need to go back through and add in notes about general visualisation stuff and bad papers for motivations
- could also help to include a bunch of papers that talk about density visualisation without mentioning uncertainty visualisation in the "context" section. (for now have left those unsorted)

##### Introduction

##### Defining Uncertainty
  - The more taxonomies I read the more convinced I am the "defining uncertainty" is the best one. Not only is it the most complete, but it also identifies WHY some uncertainties are difficult to visualise (specifically which part of the taxonomy) and suggests HOW you can best communicate these uncertainties.
    - A lot of other papers just make a comment like "oh some of these are hard to communicate" but that paper actually goes into detail instead of hand waving the problem away.
    - It also explains why the uncertainty visualisation literature focuses on a specific subset of uncertainty cases.
  - Examples
    - Null Values
    - Variance
    - Hypothesis Testing
    - Distribution
  - Combining uncertainty is also a reccurring theme in these papers
- I think it is also important to highlight if uncertainty is meta information or if it is a variable in of itself. Meta information (such as contiunity, exhangeability, etc) are usually set to specific visual features (e.g. VSUP clearly sees uncertainty as meta information)
- A lot of work that evaluates uncertainty visualisations checks to see if the mean can be gathered from a visualisation, but if we view uncertainty as meta-information, then with a high uncertainty we wouldn't want the mean to be visible
  - Also an example of why the motivation matters for these things. If you don't know "WHY" someone is using a visualisation for uncertainty and just pick the "best" one, you are going to get a visualisation that does a poor job of its task.
  - put uncertainty in the context of other meta-data of variables

##### Visualisation as a form of Uncertainty communication
- A LOT OF the work in uncertainty communication has a sub-field that is visualisation specific
  - Basically I want a brief section highlighting the importance of visualisation and discussing it in relation to other forms of uncertainty communication.
  - especially considering some uncertainty visualisation papers discuss using just a text based method to communicate uncerainty
  
##### Uncertainty visualisation best practices
  - There is also two kinds of papers, those that compare elements of a plot (like mapping uncertainty to an aesthetic) and those that compare some expression of a distribution (like a scatter plot compared to a box plot).
  - try to map back to david speigleholder paper i.e. uncertainty means lots of different things

# Previous literature review

##### Bivariate map
Depicts a bivariate map which uses a bivariate colour palette that is created by blending two single hue colour palettes. One colour represents the variable of interest while the other represents the sampling error of that variable. There are two immediate problems with this method. First of all, uncertainty is being expressed with hue and saturation which @Maceachren2012 found to be the worst aesthetics to map to uncertainty to as they don't have an intuitive interpretation. Value has a natural connection to uncertainty (lighter values equate to higher uncertainty and darker values equate to more certainty) so it is a much more appropriate choice. While the `Vizumap` data does depict areas of light and darkness, they are largely irrelevant to the uncertainty measure causing our heuristics to lead us to the incorrect conclusions. The Value-Suppressing Uncertainty Palettes (VSUP) shown in @fig-vsup maps estimates to the hue and error to the value thereby creating a more intuitive plot [@Correll2018]. Additionally, at high levels of uncertainty VSUP only has one output colour, which prevents viewers from decrypting any particular value and also avoids enforcing a binary encoding of significance [@Correll2018]. Unfortunately VSUP are not easy to combine with packages like `Vizumap` which leaves it still somewhat difficult to express this encoding in practice, however the combination of a bivariate map with VSUP has shown to improve decisions in the face of uncertainty [@Correll2018]. 


#####Taxonomy Benefits
- Distinctions at this taxonomy level seem to be important also untangling helps to understand it
  - Failing to communicate the nature of your uncertainty can result in underestimation or overestimation of failure probabilities [@Kiureghian2009]
  - @Gustafson2019 found that the framing of our uncertainty, (i.e. if the source of uncertainty is from a lack of knowledge, approximations, unknown unknowns, or disagreement among parties) was found to not have a detrimental effect on the belief in the estimates, perceived credibility, or behavioural intentions of the decision makers.

##### The benefits of Unvertainty visualisaiton
Visualisations can provide a more complete picture of a risk than numerical summaries alone. Even something as simple as sketching a distribution before recalling statistics or making predictions can greatly increase the accuracy of those measures [@Hullman2018; @Goldstein2014]. While there is some evidence that confidence intervals provided in text form only are less likely to be misinterpreted than graphics [@Savelli2013], text is insufficient to express more complicated aspects of a distribution, such as mass. Expressing uncertainty verbally decreases the perceived reliability and trustworthiness of the source [@VanderBles2020]. Any confusion caused by expressing uncertainty as a visualisation could also be due to a lack of exposure, since @Kay2016 found people repeatedly exposed to the same uncertainty visualisations quickly get better at making judgements. Additionally, visualisation allow for interactive graphics that provide a more in depth understanding of probability [@Potter2009; @Ancker2009] and infographics that make uncertainty more accessible for people with poor numeracy skills [@Ancker2009]. 
**application in energy**
The use of uncertainty in high dimensional environments is especially important in energy data. Large models that incorporate spatial-temporal data from many sources and systems are used to predict energy uses in the short and long term. Understanding how to improve and make better decisions in these models is imperative in both the daily operation of the energy sector as well as in the transition from fossil fuels to clean energy. The energy sector needs better heuristics to make energy supply analysis less costly to conduct [@Stenclik2021], therefore it is an incredibly relevant application of uncertainty visualisation techniques. 

##### People dont visualise uncertainty but it is considered important
Despite these benefits, there is evidence that we don't visualise uncertainty as often as we should. A survey conducted by @Hullman2020a found that majority of visualisation authors agreed that expressing uncertainty is important and should be done more often than it currently is, some even agreed that failing to do so is tantamount to fraud. Despite this, only a quarter of respondents included uncertainty in 50% or more of their visualisations [@Hullman2020a]. Meaning participants were convinced that visualising uncertainty is morally important but were able to provide self sufficient reasoning that allows them to avoid doing it. Some economists suggest that visualisation authors are responding to incentives that make it tempting to avoid visualising uncertainty, even if those incentives are based more in perception than reality [@Manski2020]. The study by @Hullman2020a found that the most common reasons authors don't visualise uncertainty despite knowing it's moral importance are: not wanting to overwhelm the audience; an inability to calculate the uncertainty; a lack of access to the uncertainty information; and not wanting to make their data seem questionable [@Hullman2020a].

##### Effect of uncertainty visualisation on decision making
If decision markers are not presented with the uncertainty about an estimate the data analysts have, for all intents and purposes, made the decision for the decision maker. Upon further interviews @Hullman2020a found that authors believed uncertainty would overwhelm the audience and make their data seem questionable because decision makers are unable to understand uncertainty. This belief, while pervasive, is not true. There is some research that suggests laypeople cannot understand complicated concepts in statistical thinking (such as trick questions on hypothesis tests or the difference between Frequentist and Bayesian thinking) [@Hoekstra2014; @Bella2005] but there is a large amount of research suggesting that presenting uncertainty information improves decision making, both experimentally [@Joslyn2012; @Savelli2013; @Kay2016; @Fernandes2018] and in practice [@Al-Kassab2014]. As a matter of fact, doing what many authors currently do (providing only a deterministic outcome with no uncertainty) causes decision makers to be *less* decisive and have completely unbounded expectations on an outcome [@Savelli2013]. This reality cannot be avoided by providing secondary or non-specific information such as explaining calculations [@Joslyn2012], explaining the advantages of a recommendation [@Joslyn2012], or expressing uncertainty in vague terms [@Erev_1990; @Olson_1997], all of which are undesirable for decision makers and lead to measurably worse decisions [@Joslyn2012; @Erev_1990; @Olson_1997]. One of the most popular depictions of uncertainty for decision making is a quantile dotplot, shown in @fig-quantdot. It is important to avoid whittling down the problem **too** much. Providing a categorical decision alone is somewhat useless [@Joslyn2012], and visualising a single estimate is akin to providing a decision or expressing no uncertainty at all. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-quantdot
#| fig-cap: "This plot depicts an example of a a quantile dotplot that expresses the uncertainty associated with a daily maximum temperature. The probability associated with each temperature is expressed with discrete countable bins and the predicted temperature is expressed with a line. Discretised depictions such as this, make decision making in the face of uncertainty easier for the viewer."
set.seed(1)
dotplot_data <- tibble(temp = 10 + round(rnorm(40, mean=10, sd=2))) 
mid <- round(mean(dotplot_data$temp), 2)
dotplot_data %>%
  ggplot(aes(x=temp)) +
  geom_dotplot(binwidth = 0.75, fill="grey") +
  theme_classic() +
  geom_segment(x=round(mid), xend=round(mid), 
               y=-1, yend=0.7, size=2) +
  geom_label(x=round(mid), y=0.7, label=paste0(mid, "°C"),
             fill = "black", fontface = "bold",
             colour="white") +
  scale_x_continuous(breaks = seq(10, 30, 5), 
                     limits = c(10, 30)) +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = "Tomorrow's Daily Max Temperature")
```

##### Avoiding uncertainty creates a lack of trust
Not only does communicating uncertainty improve decisions but the mistrust created by communicating certainty in uncertain situations can be exploited. A 6-month survey of anti-mask groups on Facebook during the COVID-19 pandemic showed that the anti-maskers thought carefully about their grammar of graphics and made persuasive visualisations using the same data as pro-mask groups. They did this by exploiting information ignored by the pro-maskers [@Lee2021]. It is understood that deceptive plots can lead viewers to come to incorrect conclusions or significantly overstate effects or risks [@Pandey2015; @Padilla2022] but these incorrect takeaways cannot be mitigated with instructions in how to correctly understand the plot [@Boone2018]. This evidence indicates we are more likely than not to hurt our message when we ignore uncertainty information and trying to raise the general public's plot literacy is an insufficient strategy to curb conspiracy theories and misguided scientific communication.  In direct contrast to this, displaying numerical estimates of uncertainty information has shown to lead to greater trust in predictions [@Joslyn2012; @VanderBles2020]. While @Han2009 found people have more worry when presented with uncertainty regarding health outcomes, this worry is not a bad thing if the concern is warranted given the ambiguous situation.

##### Poeple might simply be chosing to not visualise uncertainty
The disconnect between the research in support of visualising uncertainty and the consensus against it may not be entirely driven by a lack of understanding of the literature. For example, at least one interviewee from the study by @Hullman2020a claimed that expertise implies that the signal being conveyed is significant, but also said they would omit uncertainty if it obfuscated the message they were trying to convey.  Other authors who were capable of calculating and and representing uncertainty well did not do it, and were unable to provide a self-satisfying reason why [@Hullman2020a]. These conflicting motivations are acknowledged in the paper itself where @Hullman2020a says:

> "It is worth noting that many authors seemed confident in stating rationales, as though they perceived them to be truths that do not require examples to demonstrate. It is possible that rationales for omission represent ingrained beliefs more than conclusions authors have drawn from concrete experiences attempting to convey uncertainty". 



#### Continuous vs discrete displays
There are other distributional features, such as discreteness, that are important to consider in uncertainty visualisation. There is a reasonable amount of evidence that cumulative displays or discrete displays (such as a quantile dot-plots or histograms) are the best ways to express mass for decision making and probability estimates [@Fernandes2018; @Hofmann2012; Kay2016; @Hullman2018; @kale2019decision]. 

#### Distributions shoud be in a single plot
Elements from a single distribution should be displayed using a single plot, since displaying the features of one distribution across multiple plots makes the information hard to combine and results in some details (such as the estimate error) being completely ignored [@moritz2017trust; Correll2018]. 

### Perceptual tasks wrt uncertainty
Not only should we considered the hierarchy in the information we display, but we also need to consider the heuristics that connect some pieces of information to specific elementary tasks. For example @Hofmann2012 showed that polar co-ordinates are more effective than cartesian co-ordinates when considering data that depicts a 360 degree direction (a case where polar co-ordinates has a natural interpretation). Uncertainty also has a natural mapping that should be considered when we express it in a plot. Error is best mapped to fuzziness, location, and colour value; arrangement, size and transparency are an OK second choice; but saturation, hue, orientation and shape are unacceptable and have no intuitive connection to variance [@Maceachren2012]. No only do the graphical elements we map our features to matter, but the direction matters too. Graphical elements that are more fuzzy (fuzziness), further from centre (location), lighter (colour value), poorly arranged (arrangement), smaller (size), more transparent (transparency) are perceived to be more uncertain [@Maceachren2012]. This idea also extends to interval estimation, where questions about probability are best answered with gradients and questions about start and end times are easiest to answer with ambiguation [@Gschwandtnei2016]. Heuristics can work against us just as much as they can work for us. The sine illusion can cause the confidence interval of a smoothed sine curve to seem wider at the peaks than the troughs, causing us to underestimate uncertainty associated with changing values [@Vanderplas2015]. Therefore we should not only keep the hierarchy of information in mind when we map features of our distribution, but also take advantage of these intuitive mappings when we can.

